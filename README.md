# nanoGPT
Model based on [Andrej Karpathy's nanoGPT lecture](https://youtu.be/kCc8FmEb1nY)

## Basic Explanation
* Simple [Transformer model](https://arxiv.org/abs/1706.03762)
* Original Transformer model's purpose was to translate language A to B (which is why it has encoder and decoder)
* This model only has decoder since its purpose is to mimic the dataset
* This model generates texts based on Shakespeare text dataset
* Trained on A10 and A100 - I used [Lambda Labs](https://lambdalabs.com) (not sponsered, paid on my own.)

## Experiments
* These are some experiments I did by changing some parameters.

## To-dos
* Make notes for Transformer model
